@PREAMBLE{
 "\providecommand{\noopsort}[1]{}" 
 # "\providecommand{\singleletter}[1]{#1}%" 
}

% Export references in the BibTeX format online:
@MISC{ARXIVEXAMPLE,
      title={Example of an arXiv reference}, 
      author={First Author and Second Author and Third Author},
      year={2022},
      eprint={2008.00000},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@article{Cardoso2019,
  author = {Cardoso, F. and Kyriakides, S. and Ohno, S. and Penault-Llorca, F. and Poortmans, P. and Rubio, I.T. and Zackrisson, S. and Senkus, E.},
  journal = {Annals of Oncology},
  title = {Early breast cancer: ESMO Clinical Practice Guidelines for diagnosis, treatment and follow-up},
  volume = {30},
  issue = {8},
  pages = {1194--1220},
  year = {2019},
  month = {August},
  doi = {10.1093/annonc/mdz173},
}

@article{Sun2017,
  author = {Sun, Y.S. and Zhao, Z. and Yang, Z.N. and Xu, F. and Lu, H.J. and Zhu, Z.Y. and Shi, W. and Jiang, J. and Yao, P.P. and Zhu, H.P.},
  journal = {International Journal of Biological Sciences},
  title = {Risk Factors and Preventions of Breast Cancer},
  volume = {13},
  number = {11},
  pages = {1387--1397},
  year = {2017},
  month = {November},
  doi = {10.7150/ijbs.21635},
}

@misc{WHO2024,
  author = {World Health Organization},
  title = {Breast cancer},
  year = {2024}, 
  month = {March},
  url = {https://www.who.int/news-room/fact-sheets/detail/breast-cancer},
  note = {Accessed: January 30, 2025},
}

@misc{TensorFlow2024,
  author = {TensorFlow},
  title = {API Documentation (v2.16.1)},
  year = {2024},
  month = {September},
  note = {Accessed: January 30, 2025},
  url = {https://www.tensorflow.org/api_docs}
}

@misc{scikit_learn,
  author = {scikit-learn},
  title = {scikit-learn documentation â€” DevDocs},
  note = {Accessed: January 30, 2025},
  url = {https://devdocs.io/scikit_learn/}
}

@book{Bishop2006,
  author = {Bishop, Christopher M.},
  publisher = {Springer},
  title = {Pattern Recognition and Machine Learning},
  year = {2006}
}

@article{Rao2022efficient,
  author    = {Rao, Champakamala Sundar and Karunakara, K},
  title     = {Efficient Detection and Classification of Brain Tumor Using Kernel Based SVM for MRI},
  journal   = {Multimedia Tools and Applications},
  volume    = {81},
  number    = {5},
  pages     = {7393--7417},
  year      = {2022},
  note      = {Web}
}

@article{DUBEY202292,
title = {Activation functions in deep learning: A comprehensive survey and benchmark},
journal = {Neurocomputing},
volume = {503},
pages = {92-108},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.06.111},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222008426},
author = {Shiv Ram Dubey and Satish Kumar Singh and Bidyut Baran Chaudhuri},
keywords = {Activation Functions, Neural networks, Convolutional neural networks, Deep learning, Overview, Recurrent Neural Networks},
abstract = {Neural networks have shown tremendous growth in recent years to solve numerous problems. Various types of neural networks have been introduced to deal with different types of problems. However, the main goal of any neural network is to transform the non-linearly separable input data into more linearly separable abstract features using a hierarchy of layers. These layers are combinations of linear and nonlinear functions. The most popular and common non-linearity layers are activation functions (AFs), such as Logistic Sigmoid, Tanh, ReLU, ELU, Swish and Mish. In this paper, a comprehensive overview and survey is presented for AFs in neural networks for deep learning. Different classes of AFs such as Logistic Sigmoid and Tanh based, ReLU based, ELU based, and Learning based are covered. Several characteristics of AFs such as output range, monotonicity, and smoothness are also pointed out. A performance comparison is also performed among 18 state-of-the-art AFs with different networks on different types of data. The insights of AFs are presented to benefit the researchers for doing further research and practitioners to select among different choices. The code used for experimental comparison is released at: https://github.com/shivram1987/ActivationFunctions.}
}